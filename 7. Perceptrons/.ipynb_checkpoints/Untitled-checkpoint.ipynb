{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual nodes are called perceptrons, or artificial neurons, and they are the basic unit of a neural network. Each one looks at input data and decides how to categorize that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When input comes into a perceptron, it gets multiplied by a weight value that is assigned to this particular input.\n",
    "\n",
    "These weights start out as random values, and as the neural network network learns more about what kind of input data, the network adjusts the weights based on any errors in categorization that results from the previous weights. This is called TRANNING the neural network.\n",
    "\n",
    "A higher weight means the neural network considers that input more important than other inputs, and lower weight means that the data is considered less important.\n",
    "\n",
    "Each input to a perceptron has an associated weight that represents its importance. These weights are determined during the learning process of a neural network, called training.\n",
    "\n",
    "When writing equations related to neural networks, the weights will always be represented by some type of the letter w. It will usually look like a W when it represents a matrix of weights or a w when it represents an individual weight, and it may include some additional information in the form of a subscript to specify which weights\n",
    "\n",
    "The perceptron applies these weights to the inputs and sums them in a process known as linear combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the result of the perceptron's summation is turned into an output signal! This is done by feeding the linear combination into an activation function.\n",
    "\n",
    "Activation functions are functions that decide, given the inputs into the node, what should be the node's output? Because it's the activation function that decides the actual output, we often refer to the outputs of a layer as its \"activations\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
